{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2471193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import praw\n",
    "from typing import List, Tuple, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aab6fbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated as: u/None\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# AUTH (use environment vars)\n",
    "# -----------------------------\n",
    "def reddit_client():\n",
    "    return praw.Reddit(\n",
    "        client_id=\"vkf1gQoROd-7TWrnmXRtRg\",\n",
    "        client_secret=\"bJrKNBRU9HfXqSXOf2K7Wp-Mp3iIgQ\",\n",
    "        user_agent=\"LETF Scraper for MSc Thesis by u/the_ronnows\", # A descriptive user_agent is required\n",
    "        username=\"the_ronnows\",\n",
    "        password=os.environ.get('Jule9sse') # Reads the password securely\n",
    "    )\n",
    "\n",
    "reddit = reddit_client()\n",
    "print(f\"Authenticated as: u/{reddit.user.me()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3208d1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category patterns for inclusion, following your thesis design for comparative categories\n",
    "CATEGORY_KEYWORDS: Dict[str, List[str]] = {\n",
    "    \"LETF\": [\n",
    "        r\"\\bUPRO\\b\", r\"\\bTQQQ\\b\", r\"\\bSSO\\b\", r\"\\bQLD\\b\",\n",
    "        r\"\\bTMF\\b\", r\"\\bDBPG\\b\", r\"\\b3EUL\\b\", r\"\\b3QQQ\\b\",\n",
    "        r\"\\bleveraged etf\\b\", r\"\\bletf\\b\", r\"\\bvolatility decay\\b\",\n",
    "        r\"\\bleverage for the long run\\b\", r\"\\bHFEA\\b\",\n",
    "        r\"\\b2x SMA\\b\", r\"\\b3x SMA\\b\", r\"\\b9sig\\b\", r\"\\b200d SMA\\b\",\n",
    "        r\"\\bleverage rotation\\b\", r\"\\bdaily leveraged\\b\"\n",
    "    ],\n",
    "    \"Tech\": [\n",
    "        r\"\\bQQQ\\b\", r\"\\bXLK\\b\", r\"\\bVGT\\b\",\n",
    "        r\"\\btech etf\\b\", r\"\\btechnology etf\\b\", r\"\\bnasdaq 100\\b\"\n",
    "    ],\n",
    "    \"Semiconductors\": [\n",
    "        r\"\\bSOXX\\b\", r\"\\bSMH\\b\", r\"\\bXSD\\b\",\n",
    "        r\"\\bsemiconductor etf\\b\", r\"\\bchip etf\\b\"\n",
    "    ],\n",
    "    \"Commodities\": [\n",
    "        r\"\\bGLD\\b\", r\"\\bIAU\\b\", r\"\\bDBC\\b\",\n",
    "        r\"\\bcommodity etf\\b\", r\"\\bbroad commodity etf\\b\", r\"\\bgold etf\\b\",\n",
    "    ],\n",
    "    \"Broad\": [\n",
    "        r\"\\bSPY\\b\", r\"\\bVOO\\b\", r\"\\bVT\\b\", r\"\\bACWI\\b\",\n",
    "        r\"\\bworld etf\\b\", r\"\\bworld market etf\\b\", r\"\\bmarket etf\\b\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Optional long-term anchoring signals — can be toggled off in the scrape call\n",
    "LONG_TERM_ANCHORS = [\n",
    "    r\"\\blong[- ]term\\b\", r\"\\bbuy and hold\\b\", r\"\\bDCA\\b\", r\"\\bdollar[- ]cost\\b\",\n",
    "    r\"\\bretirement\\b\", r\"\\bcore holding\\b\", r\"\\bfor decades\\b\", r\"\\bISA\\b\", r\"\\b401k\\b\"\n",
    "]\n",
    "\n",
    "# Exclusions to reduce day-trading/noise and option-chatter\n",
    "GLOBAL_EXCLUSIONS = [\n",
    "    r\"\\bday[- ]trade\\b\", r\"\\bintraday\\b\", r\"\\b0DTE\\b\", r\"\\bweekly options\\b\",\n",
    "    r\"\\boptions\\b\", r\"\\bYOLO\\b\", r\"\\bswing trade\\b\", r\"\\bprice target\\b\",\n",
    "    r\"\\bscalp\\b\", r\"\\bshort squeeze\\b\", r\"\\blottery\\b\"\n",
    "]\n",
    "\n",
    "# When scraping non-LETF categories, exclude explicit LETF tickers to keep the comparison cohorts cleaner\n",
    "LETF_EXCLUSIONS = [\n",
    "    r\"\\bTQQQ\\b\", r\"\\bUPRO\\b\", r\"\\bSSO\\b\", r\"\\bQLD\\b\", r\"\\bSOXL\\b\", r\"\\bTECL\\b\",\n",
    "    r\"\\bSPXL\\b\", r\"\\b3x\\b\", r\"\\bleveraged etf\\b\", r\"\\bLETF\\b\", r\"\\bvolatility decay\\b\"\n",
    "]\n",
    "\n",
    "# Optional extra exclusions for commodities if needed\n",
    "COMMODITY_EXCLUSIONS = [\n",
    "    r\"\\bUGAZ\\b\", r\"\\bDGAZ\\b\", r\"\\bBOIL\\b\", r\"\\bKOLD\\b\",\n",
    "    r\"\\bUCO\\b\", r\"\\bSCO\\b\", r\"\\bbitcoin\\b\", r\"\\bcrypto\\b\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "672041a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_any(patterns: List[str]) -> re.Pattern:\n",
    "    if not patterns:\n",
    "        # match nothing\n",
    "        return re.compile(r\"a^\")\n",
    "    return re.compile(\"|\".join(patterns), re.IGNORECASE)\n",
    "\n",
    "def matches_any(text: str, patterns_re: re.Pattern) -> bool:\n",
    "    return bool(patterns_re.search(text or \"\"))\n",
    "\n",
    "def build_filters_for_category(category: str) -> Tuple[re.Pattern, re.Pattern, re.Pattern]:\n",
    "    inc = compile_any(CATEGORY_KEYWORDS[category])\n",
    "    anchors = compile_any(LONG_TERM_ANCHORS)\n",
    "    excl_patterns = GLOBAL_EXCLUSIONS + ([] if category == \"LETF\" else LETF_EXCLUSIONS)\n",
    "    if category == \"Commodities\":\n",
    "        excl_patterns = GLOBAL_EXCLUSIONS + COMMODITY_EXCLUSIONS + ([] if category == \"LETF\" else LETF_EXCLUSIONS)\n",
    "    excl = compile_any(excl_patterns)\n",
    "    return inc, anchors, excl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "727bde4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_category(\n",
    "    reddit: praw.Reddit,\n",
    "    asset_category: str,\n",
    "    subreddits: List[str],\n",
    "    submission_search_limit: int = 500,\n",
    "    per_thread_comment_cap: int = 150,\n",
    "    min_comment_score: int = 0,\n",
    "    time_filter: str = \"all\",        # 'all' | 'year' | 'month' | 'week'\n",
    "    require_long_term_anchor: bool = True,\n",
    "    output_dir: str = \"../data/raw/reddit_data\",\n",
    ") -> pd.DataFrame:\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    include_re, anchors_re, exclude_re = build_filters_for_category(asset_category)\n",
    "\n",
    "    rows = []\n",
    "    seen_submissions = set()\n",
    "\n",
    "    for sr in subreddits:\n",
    "        print(f\"\\n=== Scraping r/{sr} for category '{asset_category}' ===\")\n",
    "        sub = reddit.subreddit(sr)\n",
    "\n",
    "        # Build a concise query to satisfy Reddit's search constraints\n",
    "        query_terms = [p.strip(r\"\\b\").replace(\"\\\\b\", \"\") for p in CATEGORY_KEYWORDS[asset_category] if \" \" not in p]\n",
    "        query = \" OR \".join(sorted(set(query_terms[:8]))) or asset_category  # keep short\n",
    "\n",
    "        try:\n",
    "            search_iter = sub.search(query, sort=\"new\", time_filter=time_filter, limit=submission_search_limit)\n",
    "        except Exception as e:\n",
    "            print(f\"Search failed for r/{sr}: {e}\")\n",
    "            continue\n",
    "\n",
    "        for submission in search_iter:\n",
    "            if submission.id in seen_submissions:\n",
    "                continue\n",
    "            seen_submissions.add(submission.id)\n",
    "\n",
    "            post_text = f\"{submission.title}\\n{submission.selftext or ''}\"\n",
    "\n",
    "            try:\n",
    "                submission.comments.replace_more(limit=None)\n",
    "            except Exception:\n",
    "                # removed/rate-limit issue: skip this thread\n",
    "                continue\n",
    "\n",
    "            kept = 0\n",
    "            for c in submission.comments.list():\n",
    "                if kept >= per_thread_comment_cap:\n",
    "                    break\n",
    "                if getattr(c, \"body\", None) in (\"[deleted]\", \"[removed]\", None):\n",
    "                    continue\n",
    "\n",
    "                text = c.body\n",
    "\n",
    "                # Inclusion: category mention in comment OR post\n",
    "                if not matches_any(text, include_re) and not matches_any(post_text, include_re):\n",
    "                    continue\n",
    "\n",
    "                # Optional anchor requirement to bias toward long-horizon discourse\n",
    "                if require_long_term_anchor and not (matches_any(text, anchors_re) or matches_any(post_text, anchors_re)):\n",
    "                    continue\n",
    "\n",
    "                # Exclusions\n",
    "                if matches_any(text, exclude_re) or matches_any(post_text, exclude_re):\n",
    "                    continue\n",
    "\n",
    "                if c.score is not None and c.score < min_comment_score:\n",
    "                    continue\n",
    "\n",
    "                rows.append({\n",
    "                    \"asset_category\": asset_category,\n",
    "                    \"subreddit\": sr,\n",
    "                    \"submission_id\": submission.id,\n",
    "                    \"submission_title\": submission.title,\n",
    "                    \"comment_id\": c.id,\n",
    "                    \"body\": text,\n",
    "                    \"created_utc\": getattr(c, \"created_utc\", None),\n",
    "                    \"score\": getattr(c, \"score\", None),\n",
    "                    \"permalink\": f\"https://www.reddit.com{getattr(c, 'permalink', '')}\",\n",
    "                })\n",
    "                kept += 1\n",
    "\n",
    "            time.sleep(0.1)  # rate-friendliness\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if not df.empty:\n",
    "        df = df.drop_duplicates(subset=[\"subreddit\", \"submission_id\", \"comment_id\"])\n",
    "        outpath = os.path.join(\n",
    "            output_dir, f\"{asset_category.lower()}_{'-'.join([s.lower() for s in subreddits])}.csv\"\n",
    "        )\n",
    "        df.to_csv(outpath, index=False)\n",
    "        print(f\"\\nSaved {len(df):,} comments to {outpath}\")\n",
    "    else:\n",
    "        print(\"\\nNo comments matched filters.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6086ed85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Scraping r/Investing for category 'LETF' ===\n",
      "\n",
      "=== Scraping r/ETFs for category 'LETF' ===\n",
      "\n",
      "=== Scraping r/Bogleheads for category 'LETF' ===\n",
      "\n",
      "Saved 5,121 comments to ../data/raw/reddit_data/letf_investing-etfs-bogleheads.csv\n",
      "\n",
      "=== Scraping r/Investing for category 'Tech' ===\n",
      "\n",
      "=== Scraping r/ETFs for category 'Tech' ===\n",
      "\n",
      "=== Scraping r/Bogleheads for category 'Tech' ===\n",
      "\n",
      "Saved 2,218 comments to ../data/raw/reddit_data/tech_investing-etfs-bogleheads.csv\n",
      "\n",
      "=== Scraping r/Investing for category 'Semiconductors' ===\n",
      "\n",
      "=== Scraping r/ETFs for category 'Semiconductors' ===\n",
      "\n",
      "=== Scraping r/Bogleheads for category 'Semiconductors' ===\n",
      "\n",
      "Saved 2,952 comments to ../data/raw/reddit_data/semiconductors_investing-etfs-bogleheads.csv\n",
      "\n",
      "=== Scraping r/Investing for category 'Commodities' ===\n",
      "\n",
      "=== Scraping r/ETFs for category 'Commodities' ===\n",
      "\n",
      "=== Scraping r/Bogleheads for category 'Commodities' ===\n",
      "\n",
      "Saved 2,116 comments to ../data/raw/reddit_data/commodities_investing-etfs-bogleheads.csv\n",
      "\n",
      "=== Scraping r/Investing for category 'Broad' ===\n",
      "\n",
      "=== Scraping r/ETFs for category 'Broad' ===\n",
      "\n",
      "=== Scraping r/Bogleheads for category 'Broad' ===\n",
      "\n",
      "Saved 5,471 comments to ../data/raw/reddit_data/broad_investing-etfs-bogleheads.csv\n",
      "\n",
      "Total collected across categories: 17,878\n",
      "Saved combined dataset to: ../data/raw/reddit_data/reddit_master_longterm_anchored.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_category</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>permalink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LETF</td>\n",
       "      <td>Investing</td>\n",
       "      <td>1o4yopa</td>\n",
       "      <td>Does anyone hedge their portfolios with invers...</td>\n",
       "      <td>nj5xftk</td>\n",
       "      <td>Daily rebalanced leveraged inverse ETFs have a...</td>\n",
       "      <td>1.760302e+09</td>\n",
       "      <td>4</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/1o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LETF</td>\n",
       "      <td>Investing</td>\n",
       "      <td>1o4yopa</td>\n",
       "      <td>Does anyone hedge their portfolios with invers...</td>\n",
       "      <td>nj9gr5i</td>\n",
       "      <td>inverse ETFs are intended for short-term tradi...</td>\n",
       "      <td>1.760359e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/1o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LETF</td>\n",
       "      <td>Investing</td>\n",
       "      <td>1o4yopa</td>\n",
       "      <td>Does anyone hedge their portfolios with invers...</td>\n",
       "      <td>nlvxnzm</td>\n",
       "      <td>You're buying an asset with negative expected ...</td>\n",
       "      <td>1.761682e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/1o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LETF</td>\n",
       "      <td>Investing</td>\n",
       "      <td>1nui8ye</td>\n",
       "      <td>10-Year Hold Plan with NBIS, DPRO, and HGRAF –...</td>\n",
       "      <td>nh1svaj</td>\n",
       "      <td>Added nbis to my forever hold, now ballooned t...</td>\n",
       "      <td>1.759256e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/1n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LETF</td>\n",
       "      <td>Investing</td>\n",
       "      <td>1nui8ye</td>\n",
       "      <td>10-Year Hold Plan with NBIS, DPRO, and HGRAF –...</td>\n",
       "      <td>nh422vy</td>\n",
       "      <td>Your submission has been automatically removed...</td>\n",
       "      <td>1.759282e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/1n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LETF</td>\n",
       "      <td>Investing</td>\n",
       "      <td>1n7uw7b</td>\n",
       "      <td>Whats wrong with a 23 year old investing into ...</td>\n",
       "      <td>ncabok0</td>\n",
       "      <td>High expense ratios, volatility decay</td>\n",
       "      <td>1.756944e+09</td>\n",
       "      <td>293</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/1n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LETF</td>\n",
       "      <td>Investing</td>\n",
       "      <td>1n7uw7b</td>\n",
       "      <td>Whats wrong with a 23 year old investing into ...</td>\n",
       "      <td>ncaczbp</td>\n",
       "      <td>S&amp;P 500 vs. S&amp;P 500 3x over the past 140 years...</td>\n",
       "      <td>1.756944e+09</td>\n",
       "      <td>98</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/1n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LETF</td>\n",
       "      <td>Investing</td>\n",
       "      <td>1n7uw7b</td>\n",
       "      <td>Whats wrong with a 23 year old investing into ...</td>\n",
       "      <td>ncaby74</td>\n",
       "      <td>Probably not a good idea. Leveraged ETF's are ...</td>\n",
       "      <td>1.756944e+09</td>\n",
       "      <td>119</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/1n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LETF</td>\n",
       "      <td>Investing</td>\n",
       "      <td>1n7uw7b</td>\n",
       "      <td>Whats wrong with a 23 year old investing into ...</td>\n",
       "      <td>ncakl2l</td>\n",
       "      <td>2x is better for buy and hold than 3x if you h...</td>\n",
       "      <td>1.756947e+09</td>\n",
       "      <td>8</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/1n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LETF</td>\n",
       "      <td>Investing</td>\n",
       "      <td>1n7uw7b</td>\n",
       "      <td>Whats wrong with a 23 year old investing into ...</td>\n",
       "      <td>ncciu6n</td>\n",
       "      <td>\"Twenty-three year old men who 'invest' all th...</td>\n",
       "      <td>1.756981e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/1n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  asset_category  subreddit submission_id  \\\n",
       "0           LETF  Investing       1o4yopa   \n",
       "1           LETF  Investing       1o4yopa   \n",
       "2           LETF  Investing       1o4yopa   \n",
       "3           LETF  Investing       1nui8ye   \n",
       "4           LETF  Investing       1nui8ye   \n",
       "5           LETF  Investing       1n7uw7b   \n",
       "6           LETF  Investing       1n7uw7b   \n",
       "7           LETF  Investing       1n7uw7b   \n",
       "8           LETF  Investing       1n7uw7b   \n",
       "9           LETF  Investing       1n7uw7b   \n",
       "\n",
       "                                    submission_title comment_id  \\\n",
       "0  Does anyone hedge their portfolios with invers...    nj5xftk   \n",
       "1  Does anyone hedge their portfolios with invers...    nj9gr5i   \n",
       "2  Does anyone hedge their portfolios with invers...    nlvxnzm   \n",
       "3  10-Year Hold Plan with NBIS, DPRO, and HGRAF –...    nh1svaj   \n",
       "4  10-Year Hold Plan with NBIS, DPRO, and HGRAF –...    nh422vy   \n",
       "5  Whats wrong with a 23 year old investing into ...    ncabok0   \n",
       "6  Whats wrong with a 23 year old investing into ...    ncaczbp   \n",
       "7  Whats wrong with a 23 year old investing into ...    ncaby74   \n",
       "8  Whats wrong with a 23 year old investing into ...    ncakl2l   \n",
       "9  Whats wrong with a 23 year old investing into ...    ncciu6n   \n",
       "\n",
       "                                                body   created_utc  score  \\\n",
       "0  Daily rebalanced leveraged inverse ETFs have a...  1.760302e+09      4   \n",
       "1  inverse ETFs are intended for short-term tradi...  1.760359e+09      2   \n",
       "2  You're buying an asset with negative expected ...  1.761682e+09      1   \n",
       "3  Added nbis to my forever hold, now ballooned t...  1.759256e+09      2   \n",
       "4  Your submission has been automatically removed...  1.759282e+09      1   \n",
       "5              High expense ratios, volatility decay  1.756944e+09    293   \n",
       "6  S&P 500 vs. S&P 500 3x over the past 140 years...  1.756944e+09     98   \n",
       "7  Probably not a good idea. Leveraged ETF's are ...  1.756944e+09    119   \n",
       "8  2x is better for buy and hold than 3x if you h...  1.756947e+09      8   \n",
       "9  \"Twenty-three year old men who 'invest' all th...  1.756981e+09      9   \n",
       "\n",
       "                                           permalink  \n",
       "0  https://www.reddit.com/r/investing/comments/1o...  \n",
       "1  https://www.reddit.com/r/investing/comments/1o...  \n",
       "2  https://www.reddit.com/r/investing/comments/1o...  \n",
       "3  https://www.reddit.com/r/investing/comments/1n...  \n",
       "4  https://www.reddit.com/r/investing/comments/1n...  \n",
       "5  https://www.reddit.com/r/investing/comments/1n...  \n",
       "6  https://www.reddit.com/r/investing/comments/1n...  \n",
       "7  https://www.reddit.com/r/investing/comments/1n...  \n",
       "8  https://www.reddit.com/r/investing/comments/1n...  \n",
       "9  https://www.reddit.com/r/investing/comments/1n...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure cohorts and run\n",
    "SUBREDDITS = [\"Investing\", \"ETFs\", \"Bogleheads\"]  # include r/LETFs for in-group discussion\n",
    "CATEGORIES = [\"LETF\", \"Tech\", \"Semiconductors\", \"Commodities\", \"Broad\"]\n",
    "\n",
    "# Collection knobs\n",
    "SUBMISSION_SEARCH_LIMIT = 400\n",
    "PER_THREAD_COMMENT_CAP = 100\n",
    "MIN_COMMENT_SCORE = 0\n",
    "TIME_FILTER = \"all\"                  # change to 'all' to expand\n",
    "REQUIRE_LONG_TERM_ANCHOR = True       # set False to broaden collection\n",
    "\n",
    "dfs = []\n",
    "for cat in CATEGORIES:\n",
    "    df_cat = scrape_category(\n",
    "        reddit=reddit,\n",
    "        asset_category=cat,\n",
    "        subreddits=SUBREDDITS,\n",
    "        submission_search_limit=SUBMISSION_SEARCH_LIMIT,\n",
    "        per_thread_comment_cap=PER_THREAD_COMMENT_CAP,\n",
    "        min_comment_score=MIN_COMMENT_SCORE,\n",
    "        time_filter=TIME_FILTER,\n",
    "        require_long_term_anchor=REQUIRE_LONG_TERM_ANCHOR,\n",
    "        output_dir=\"../data/raw/reddit_data\",\n",
    "    )\n",
    "    if not df_cat.empty:\n",
    "        dfs.append(df_cat)\n",
    "\n",
    "df_all = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame(columns=[\n",
    "    \"asset_category\",\"subreddit\",\"submission_id\",\"submission_title\",\n",
    "    \"comment_id\",\"body\",\"created_utc\",\"score\",\"permalink\"\n",
    "])\n",
    "\n",
    "print(f\"\\nTotal collected across categories: {len(df_all):,}\")\n",
    "\n",
    "# Master dump to support downstream NLP/regression phases\n",
    "master_out = \"../data/raw/reddit_data/reddit_master_longterm_anchored.csv\" if REQUIRE_LONG_TERM_ANCHOR else \"../data/raw/reddit_data/reddit_master.csv\"\n",
    "df_all.to_csv(master_out, index=False)\n",
    "print(f\"Saved combined dataset to: {master_out}\")\n",
    "\n",
    "# Preview\n",
    "df_all.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7254771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9b410d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46580e55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
